{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">\n",
    "\n",
    "# Информация\n",
    "\n",
    "## Передача сообщений\n",
    "\n",
    "Если ифнормация, переданная в сообщении, известна _заранне_, или _a priori_, то количество ифнормации, переданной в сообщении, равно нулю. Потому что ничего нового из сообщения мы не узнали.\n",
    "\n",
    "Но если ифнормация, которая подтверждается сообщением, еще не известна точно, но только с некоторой вероятностью $p$? Тогда сообщение, очевидно, содержит новую информацию. \n",
    "\n",
    "Пример: вы капитан корабля и вы знаете, что половина всех кораблей в Карибском море - пиратские. Корабль, который вы видите, еще не поднял флага, и вы не знаете, что это за корабль.\n",
    "\n",
    "Как только флаг поднят, вы получаете повую порцию информации - так как другой корабль передал вам сообщение, обозначил себя как пиратский или \"мирный\".\n",
    "\n",
    "<img src=\"files/roger.jpg\">\n",
    "\n",
    "Хороший вопрос - как измерять количество переданной в сообщении информации?\n",
    "\n",
    "Некоторое \"наивное\" представление говорит, что количество переданной в сообщении информации может быть сзязано с битами. Логично предположить, что флаг корабля можно представить как один бит информации:\n",
    "\n",
    "$$\\{0 - корабль\\ обычный, 1 - корабль\\ пирасткий\\}$$\n",
    "\n",
    "Подняли флаг - передали один бит. Но, вообще говоря, это верно не всегда, а только когда корабли рапределены поровну между пиратами и \"не пиратами\".\n",
    "\n",
    "### На самом деле немного сложнее\n",
    "\n",
    "Более реалистичная ситуация - допустим, всего $\\dfrac{1}{8}$ кораблей является пиратскими. \n",
    "\n",
    "Итак, капитан корабля предполагает, что с вероятностью 1/8 другой корабль является пиратским. Равноценно ли \"сообщение\", которое передает флаг, \n",
    "\n",
    "* Когда корабль пиратский?\n",
    "* Когда корабль не пирасткий?\n",
    "\n",
    "Казалось бы, все равно. Но на самом деле, информация о _болеее редком_, менее вероятном событии представляет больший интерес (не только с точки зрения теории информации, но и с точки зрения капитана, т.е. условного \"получателя сообщения\").\n",
    "\n",
    "И _сколько_ информации при этом будет передано?\n",
    "\n",
    "#### Немного другой пример\n",
    "\n",
    "Если товарищ подсказывает, какой из двух ответов на вопрос теста правильный, он передает вам 1 бит информации.\n",
    "\n",
    "А если подсказать два ответа на два вопроса, с двумя вариантами ответов каждый? \n",
    "\n",
    "> По идее, должно быть два бита.\n",
    "\n",
    "- Три вопроса? Четыре?\n",
    "- Если дали подсказку, какой вариант из семи правильный? Из восьми?\n",
    "\n",
    "\n",
    "### Вывод формулы собственной информации\n",
    "\n",
    "Если вероятность события $w_i$ равна 1 (всех пиратов поймали), то передача информации (подъем флага) не несет важной ифнормации; количество переданной информации должно быть равно $I(w_i) = 0$.\n",
    "\n",
    "Если вероятность события $w_i$ меньше нуля, то количество информации $I(w_i) > 0$\n",
    "\n",
    "Если два независимых события происходят \"одновременно\", то количество информации, переданное в сообщении о том, что случились эти два события, должна быть равна сумме ифнормации сообщений об отдельных событиях.\n",
    "\n",
    "То есть, например, \n",
    "\n",
    "- Если 1/8 кораблей - пиратские, и 1/8 капитанов - испанцы (предположим, нет никакой связи между национальностью капитана и \"пиратскостью корабля\"), то количество информации от одновременно ипиратского и испанского флагов равно сумме информации отдельно от пиратского и от испанского флагов\n",
    "\n",
    "> $I(Пиратский, Испанский) = I(Пиратский) + I(Испанский) $\n",
    "\n",
    "Та же логика с подсказкой ответов на тесты:\n",
    "\n",
    "> $I(Ответ\\ 1, Ответ\\ 2) = I(Ответ\\ 1) + I(Ответ\\ 2) $\n",
    "\n",
    "**Важно!** В случае, если один из правильных ответов вам известен (например, ответ на второй вопрос) - количество информации, переданной во втором сообщении будет равно нулю. Потому что это событие уже _определено_ для вас, вероятность его равна $1$.\n",
    "\n",
    "Так что тогда, фактически, вам передали $1$ бит новой информации.\n",
    "\n",
    "Определим функцию, которая удовлетворяет критириям, перечисленным выше, и \"превращает\" вероятнсоть события в собственную информацию.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "I(w_1\\cap w_2) &= I(w_1) + I(w_2) \\notag \\\\\n",
    "f(P(w_1\\cap w_2)) &= f(P(w_1)) + f(P(w_2))  \\notag \\\\\n",
    "&= f(P(w_1)\\cdot P(w_2))  \\notag \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Последнее равенство верно, потому что вероятность одновременного появления двух _независимых_ событий равна произведению вероятнсотей этих событий.\n",
    "\n",
    "Окей, что за функция $f(x\\cdot y) = f(x) + f(y)$?\n",
    "\n",
    "> Логарифм! Точнее, здесь используется $K\\log {x}$\n",
    "\n",
    "Так как $0 \\leq P(w_i) \\leq 1$, их логарифм будет отрицательным. Отсюда вытекает значение константы $K < 0$. Для \"бинарного\" случая и двоичного логарифма используется $-1$.\n",
    "\n",
    "\n",
    "В итоге, \n",
    "\n",
    "$I(P(w_i)) = -\\log_2 {P(w_i)} = \\log_2 {\\dfrac{1}{P(w_i)}} $\n",
    "\n",
    "\n",
    "\n",
    "Как вариант, информацию иногда записывают через случайную переменную $X$ для состояния переменной $x$:\n",
    "\n",
    "$I_X(x) = -\\log_2 {p_X(x)} = \\log_2 {\\dfrac{1}{p_X(x)}} $\n",
    "\n",
    "\n",
    "Для энтропии, определенной через двоичный логарифм, единица измерений - бит (что особенно хорошо совместимо с ситуацией, когда появления \"значений\" равновероятны и неопределны - 1 бит - 1 бит :) ).\n",
    "\n",
    "## Энтропия\n",
    "\n",
    "Энтропия в теории информации - это математическое ожидание собственной ифнормации.\n",
    "\n",
    "$$H(X) = E[I(X)] = E[-log {P(X)}]$$\n",
    "\n",
    "Если предположить, что $X$ может принимать $n$ значений с вероятностями $\\{P(x_1), P(x_2), ..., P(x_n)\\}$ - как записать математическое ожидание?\n",
    "\n",
    "\n",
    "**Энтропия Шеннона:**\n",
    "\n",
    "$H(X) = - \\sum\\limits_{i=1}^{n}P(x_i) \\cdot \\log {P(x_i)}$\n",
    "\n",
    "\n",
    "Шеннон основывал свои рассуждения на следующих свойствах энтропии:\n",
    "\n",
    "- $I(p)$ монотонна\n",
    "- $I(p) \\geq 0$ - информация неотрицательна\n",
    "- $I(1) = 0$ - гарантированно случающиеся события не создают (новой) информации\n",
    "- $I(p_1, p_2) = I(p_1) + I(p_2)$ - информация независимых событий аддитивна\n",
    "\n",
    "для который отлично подходит (если решить определенную систему дифференциальных уравнений) функция $I(x) = k \\log{x}$.\n",
    "\n",
    "За N сообщений конкретная реализация $w_i$ случится $NP(w_i) = n_i$ раз, тогда для всех событий будет\n",
    "\n",
    "$$\\sum\\limits_{i}n_i I(w_i) = -\\sum\\limits_{i}NP(w_i)\\log {P(w_i)}$$\n",
    "\n",
    "поделим на $N$, получим среднее количество информации (мат. ожидание) на одно событие\n",
    "\n",
    "$$ - \\sum\\limits_{i}P(w_i)\\log {P(w_i)}$$\n",
    "\n",
    "$$ \\sum\\limits_{i}P(w_i) I(w_i)$$\n",
    "\n",
    "\n",
    "### Совместная энтропия (Joint entopy)\n",
    "\n",
    "Совместная энтропия базируется на совместной вероятности (совместное распределение). Та же идея, что и для энтропии Шеннона, но уже для набора переменных.\n",
    "\n",
    "> Например, в нашем \"пиратском\" случае можно говорить о совместном распределении типа корабля и национальной принадлежности корабля. При этом \"пиратскость\" и национальность, скорее всего, не независимые переменные.\n",
    "\n",
    "> Для броска двух игральных костей также можно построить совместное распределение. \n",
    "\n",
    "Совместная энтропия:\n",
    "\n",
    "$$H(X_1, ..., X_n) = - \\sum\\limits_{x_1 \\in X_1, ..., x_n \\in X_n} p(x_1, ..., x_n) \\log {p(x_1, ...,x_n)}$$\n",
    " \n",
    "\n",
    "\n",
    "### Условная энтропия\n",
    "\n",
    "Условная энтропия - это энтропия события $Y$ при условии события $X$. Фактически, это матожидание количества информации, которое передается в $Y$, когда значение $X$ известно.\n",
    "\n",
    "$$H(Y|X) = -\\sum\\limits_{x \\in X, y \\in Y} p(x,y) \\log{\\dfrac{p(x,y)}{p(x)}}$$\n",
    "\n",
    "> $0 \\log {c/0}$ по соглашению равен $0$ (также это значение $\\lim\\limits_{x \\to +0}x \\log {c/x}$)\n",
    "\n",
    "Здесь $p(x, y)$ - вероятность совместного появления $x$ и $y$.\n",
    "\n",
    "Условная энтропия нужна, когда события $x,y$ зависимы. Например, пиратов может быть больше среди испанцев, тогда информация о том, что капитан - испанец, несколько \"снижает\" ценность последующей информации о том, что корабль - пиратский.\n",
    "\n",
    "Окей. Допустим, в акватории есть только испанские и голландские корабли, голандских кораблей - $1/4$, распределение пиратских и торговых кораблей такое:\n",
    "\n",
    "<pre>\n",
    "    P.  M.\n",
    "D. 1/8 7/8\n",
    "S. 1/4 3/4\n",
    "</pre>\n",
    "\n",
    "\n",
    "#### Условная энтропия (conditional entropy)\n",
    "\n",
    "Какова энтропия $H(Y|X) = \\sum\\limits_{x \\in X}H(Y|X = x)$?\n",
    "\n",
    "То есть сколько в среднем мы получим информации, зная, пиратский корабль, или нет?\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "H(Y,X) &= - \\bigg(\\dfrac{p(D,P)log(D,P) + p(D,M)log(D,M)}{p(D)} + \\dfrac{p(S,P)log(S,P) + p(S,M)log(S,M)}{p(S)}\\bigg) \\notag \\\\\n",
    "&= - \\bigg(\\dfrac{1/8 \\cdot log(1/8) + 7/8 \\cdot log(7/8)}{1/4} + \\dfrac{1/4 \\cdot log(1/4) + 3/4 \\cdot log(3/4)}{3/4} \\bigg) \\notag \\\\\n",
    "&=3.256\n",
    "\\end{align} \n",
    "$$\n",
    "\n",
    "\n",
    "#### Вопросы:\n",
    "- Когда $H(Y|X) = 0$?\n",
    "- Когда $H(Y|X) = H(Y)$?   \n",
    "(опишите зависимость $X$ и $Y$)\n",
    "\n",
    "- $H(Y|X) = 0$, когда $Y$ полностью определено $X$\n",
    "- $H(Y|X) = H(Y)$, когда случайные переменные $X,Y$ независимы.\n",
    "\n",
    "### Chain rule\n",
    "$H(Y|X) = H(X,Y) - H(X)$\n",
    "\n",
    "$H(X_1, X_2, ..., X_n) = \\sum\\limits_{i=1}^{n}H(X_i|X_1, X_2, ...,X_{i-1})$\n",
    "\n",
    "Формула, аналогичная chain rule для вероятности:\n",
    "\n",
    "\n",
    "$\\mathrm  P(X_n \\cap \\ldots \\cap X_1)  = \\prod_{i=1}^n  \\mathrm P\\left(X_i \\,\\Bigg|\\, \\bigcap_{j=1}^{i-1} X_j\\right)$\n",
    "\n",
    "> Вообще, формулы для вероятности, имеющие \"осмысленные\" аналоги для энтропии, получаются заменой деления/умножения вычитанием/сложением.\n",
    "\n",
    "\n",
    "## Применение к кодам Хаффмана\n",
    "\n",
    "Старая, добрая $GATTACA$. Давайте оценим оптимальность кодировки.\n",
    "\n",
    "$M = \\{A, C, G, T\\}$  \n",
    "\n",
    "$P(A) = 3/7, P(T) = 2/7, P(C) = P(G) = 1/7$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "&A \\to 0 \\notag \\\\\n",
    "&T \\to 10 \\notag \\\\\n",
    "&C \\to 111 \\notag \\\\\n",
    "&G \\to 110 \\notag \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Сколько бит информации _в среднем_ требуется, чтобы передать один символ?\n",
    "\n",
    "$\\sum\\limits_i p(M_i) \\cdot (bits\\ of\\ M_i) = 2.1429$\n",
    "\n",
    "А какой теоретический предел сжатия информации для данного набора символов и текста?\n",
    "\n",
    "$H(M) = \\sum\\limits_i p(M_i) \\log {p(M_i)} = 1.8424$\n",
    "\n",
    "\n",
    "### Избыточность информации\n",
    "\n",
    "Уже более практическая вещь: она встретится в контексте кодировок, а так же связана с максимально возможным сжатием.\n",
    "\n",
    "Определяется через \"плотность информации\" от случайного процесса (rate):\n",
    "\n",
    "$$r = \\lim\\limits_{n \\to \\inf} \\dfrac{1}{n}H(M_1, M_2, ...,M_n)$$\n",
    "\n",
    "> $M = \\{M_1, M_2, ...,M_n\\}$ - символы алфавита\n",
    "\n",
    "$R = \\log |M|$ - максимальное количество информации, которе может быть передано при помощи алфавита $M$, если кодировка не избыточна. \"Идеальные улсовия\" - если текущее состояние не зависит от предыдущих, появления символов равновероятны.\n",
    "\n",
    "Абсолютная избыточность - $D = R - r$; Относителльная избыточность - \n",
    "\n",
    "$$\\dfrac{R-r}{R} = \\dfrac{\\log{|M|} - \\lim\\limits_{n \\to \\inf} \\dfrac{1}{n}H(M_1, M_2, ...,M_n)}{\\log {|M|}}$$\n",
    "\n",
    "\\- равна максимальному теоретически возможному сжатию источника данных (вспомните алгоритмы, которые разбирали на прошлом занятии).\n",
    "\n",
    "\n",
    "### Пример избыточности текста\n",
    "\n",
    "Строка 'AAAACCAACCCCAACAC...' - всегда только из 'AA' и 'СС', появляющихся независимо друг от друга и с равной вероятностью.\n",
    "\n",
    "$M = \\{A, C\\}$\n",
    "\n",
    "$R = \\log {2} = 1$\n",
    "\n",
    "$r = 1/2$\n",
    "\n",
    "$( R - r  )/ R = 1/2$; строку можно сжать в два раза\n",
    "\n",
    "TBD:\n",
    "- добавлю расчет $r$ для этой строки\n",
    "- добавлю пример с настоящим генетичеким кодом и триплетами\n",
    "\n",
    "\n",
    "### Совместная информация\n",
    "\n",
    "Полезна как теоретический критерий для оценки качества шифра: должна быть равна $0$ в случае, когда шифр оптимален.\n",
    "\n",
    "$I(X,Y) = H(X) - H(X|Y)$\n",
    "\n",
    "> Вопрос: вспоминая предыдущие определения - почему $I(X,Y)$ должна быть равна нулю?\n",
    "\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">\n",
    "\n",
    "# Типы шифрования\n",
    "\n",
    "## Симметричное шифрование\n",
    "\n",
    "- Для шифрования и расшифровки используется один и тот же ключ\n",
    "- Базово, операции шифрования и расшифровки комбинируются из P-box'ов (перестановки) и S-box'ов (подстановки)\n",
    "- Возникает проблема передачи ключа\n",
    "- Примеры: DES, AES\n",
    "\n",
    "## Асимметричное шифрование\n",
    "\n",
    "- Есть пара ключей - открытый и закрытый\n",
    "- Открытый ключ используется для шифрования, а закрытый - для дешифрования сообщения\n",
    "- Открытый ключ можно передавать по общедоступным каналам\n",
    "- Часто алгоритмы асимметричного шифрования используются для того, чтобы перед передачей зашифровать ключ алгоритма симметричного шифрования (которые, как правило, быстрее)\n",
    "- Примеры: RSA, Elgamal (Эль-Гамаль), Rabin\n",
    "- Ключ больше, чем в симметричном шифровании\n",
    "- Медленнее, сложнее вычислительно\n",
    "\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">\n",
    "\n",
    "# Симметричное шифрование\n",
    "\n",
    "## Запутанность (конфузия) и диффузия\n",
    "\n",
    "#### Запутанность\n",
    "\n",
    "Количество бит ключа, от который зависит каждый бит зашифрованного сообщения. Запутанность делает зависимость входных данных и шифротекста нелинейной, реализуется, в основном, через S-блоки\n",
    "\n",
    "#### Диффузия\n",
    "\n",
    "\"Рассредоточненность\" части оригинального сообщения на зашиврованное, т.е. от одного бита сообщения должно зависеть состояние _многих_ битов зашифрованной версии.  \n",
    "\n",
    "Диффузия \"распределяет\" избыточную информацию из исходного текста по всему шифротексту. \n",
    "\n",
    "- Сложнее делать выводы о составе ключа по шифротексту\n",
    "- Сложнее определить текст, зная часть ключа\n",
    "- Работа основана на перестановках (P-боксы)\n",
    "\n",
    "В идеале, изменение любого бита $i$ текста должно с вероятсностью $\\dfrac{1}{2}$ менять состояние произвольного бита ключа $j$.\n",
    "\n",
    "### Лавинный эффект (avalanche effect)\n",
    "\n",
    "Изменение малого количества битов в ключе или входных данных приводит к \"лавине\" изменений в шифротексте.\n",
    "\n",
    "#### Нестрогий критерий\n",
    "\n",
    "Изменение одного бита на входе функции $f: \\{0, 1\\}^n \\to \\{0, 1\\}^n$ приводит к изменению примерно полвины битов на выходе для \n",
    "\n",
    "#### Строгий лавинный критерий\n",
    "\n",
    "Для булевой функции $f(x \\in \\{0,1\\}^n)$ изменение одного входного бита меняет состояние с вероятностью ровно $1/2$.\n",
    "\n",
    "Напишите функцию, удовлетворяющую строгому лавинному критерию для $\\{0, 1\\}^2$ (двухбитовых строк)\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "&00 \\to ? \\notag \\\\\n",
    "&01 \\to ? \\notag \\\\\n",
    "&10 \\to ? \\notag \\\\\n",
    "&11 \\to ? \\notag \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "<img src=\"files/avalanche_strict_schema.png\">\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "&f: 00 \\to 0 \\notag \\\\\n",
    "&f: 01 \\to 0 \\notag \\\\\n",
    "&f: 10 \\to 1 \\notag \\\\\n",
    "&F: 11 \\to 1 \\notag \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    "## S-box\n",
    "\n",
    "Подстановка одних значений на место других. \n",
    "\n",
    "<img src=\"files/Dancing_men.jpg\">\n",
    "\n",
    "\n",
    "## P-box\n",
    "\n",
    "Перемешивание значений. \n",
    "<img src=\"files/p_box.png\">\n",
    "\n",
    "Основной вопрос - как включить в S- и P-боксы ключ, чтобы сделать процесс шифрования обратимым?\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">\n",
    "\n",
    "## DES\n",
    "\n",
    "В DES (Data Encryption Standart) P-box и S-box объединены в одну функцию для шифрования - функцию Фейстеля.\n",
    "\n",
    "\n",
    "### Применение F-функции для шифрования и расшифровки\n",
    "\n",
    "Есть набор ключей: $K_0, K_1, ...,K_n$\n",
    "\n",
    "Текст для шифрования разделяется на правую ($R$) и левую ($L$) части\n",
    "\n",
    "Шифрование выполняется итеративным выполнением операций:\n",
    "\n",
    "$L_{i+1} = R_i$  \n",
    "$R_{i+1} = L_i \\oplus F(R_i, K_i)$\n",
    "\n",
    "$(R_{n+1}, L_{n+1})$ представляет собой зашифрованный текст (обратите внимание не перестановку $R$ и $L$.\n",
    "\n",
    "Для расшифровки ключи применяются в обратном порядке: \n",
    "\n",
    "$R_i = L_{i+1}$  \n",
    "$L_i = R_{i+1} \\oplus F(L_{i+1}, K_{i})$\n",
    "\n",
    "$(L_0, R_0)$ - результат декодирования - расшифрованный текст, тождественный оригинальному\n",
    "\n",
    "<img src=\"Feistel_cipher_diagram_en.svg\" width=350>\n",
    "\n",
    "### Корректность применения F-функции\n",
    "\n",
    "Набор операций шифрования, фактически, делает следующее:\n",
    "\n",
    "$(L, R) \\to (L \\oplus F(R, K), R)$\n",
    "\n",
    "Свойство операции $XOR$?\n",
    "\n",
    "$$X \\oplus Y \\oplus Y = X$$\n",
    "\n",
    "Тогда \n",
    "\n",
    "$(L \\oplus F(R, K) \\oplus F(R, K), R) = (L, R) $  \n",
    "\n",
    "\\- применение шага дешифровки!\n",
    "\n",
    "- Мы можем соединить подряд столько операций, сколько нам нужно \n",
    "- Функция $F$ не обязательно должна быть обратимо\n",
    "\n",
    "> Например, в AES для расшифровки должны использоваться обратные к S- и P-боксу функции.\n",
    "\n",
    "### Пример работы\n",
    "\n",
    "Попробуем сделать 1 шаг схемы шифрования Фейстеля, а затем выполнить дешифровку.\n",
    "\n",
    "Сообщение: $1110$  \n",
    "Ключ: $01$  \n",
    "$L = 11, R = 10$  \n",
    "\n",
    "Давайте еще определим $F$ как $F(x, k)$ = $P(S(x \\oplus k))$,\n",
    "\n",
    "$S$ как отображение\n",
    "$00 \\to 10$  \n",
    "$01 \\to 11$  \n",
    "$10 \\to 00$  \n",
    "$11 \\to 10$  \n",
    "\n",
    "\n",
    "и $P$ как перестановку \n",
    "\n",
    "$$\n",
    "P = \\begin{pmatrix}\n",
    "0 & 1 \\\\\n",
    "1 & 0\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "#### Зашифровка\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "(11 \\oplus F(10, 01), 10) &= (11 \\oplus P(S(11)), 10) \\notag \\\\\n",
    "&= (11 \\oplus P(10), 10) \\notag \\\\\n",
    "&= (11 \\oplus 01, 10) \\notag \\\\\n",
    "&= (10, 10)  \\notag \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    "#### Расшифровка\n",
    "$$\n",
    "\\begin{align}\n",
    "(10 \\oplus F(10, 01), 10) &= (10 \\oplus 01, 10) \\notag \\\\\n",
    "&= (11, 10) \\notag \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "### F-функция DES\n",
    "\n",
    "На изображении - конкретная реализация f-функции, используемая в DES.\n",
    "\n",
    "<img src=\"files/DES-f-function.png\" width=400>\n",
    "\n",
    "\n",
    "Есть несколько особенностей, связанных с практическими аспектами - скоростью работы и тем, что на практике часть информации теряется, и, например, часть битов используется как биты четности для проверки корректности.\n",
    "\n",
    "\n",
    "<div style=\"display:flex\">\n",
    "     <div style=\"flex:1;padding-right:5px;\">\n",
    "          <img src=\"files/DES-main-network.png\" width=\"195\">\n",
    "     </div>\n",
    "     <div style=\"flex:1;padding-left:5px;\">\n",
    "          <img src=\"files/DES-key-schedule.png\" width=\"300\">\n",
    "     </div>\n",
    "</div>\n",
    "\n",
    "\n",
    "- На входе и выходе DES добавлена перестановка. Перестановка на выходе является обратной к перестановке на входе\n",
    "- Длина слова - 64 бита, делится на блоки по 32\n",
    "- Размер ключа - 64 бита, но! 8 бит используются для проверки четности, а на каждом шаге ключа осуществляется сдвиг, а из ключа выбирается 48 бит для кодирования\n",
    "- Перед подстановкой на блок из 32 двух бит применяется операция $E$ (Extension), переводящая блок в 48 бит\n",
    "- Затем $E(L) \\oplus K$ - XOR расширенной последовательности и ключа\n",
    "- Операция подстановки $S$, S-box, отображает 6-битные блоки в 4-х битные, т.е. получается преобразование из 48-битной в 32-битную размерность\n",
    "- Проводится перестановка по стандартной таблице, можно переходить к следующему шагу\n",
    "- Всего 16 шагов\n",
    "\n",
    "> [По ссылке таблицы для DES](https://en.wikipedia.org/wiki/DES_supplementary_material)\n",
    "\n",
    "### Лавинный эффект в DES\n",
    "\n",
    "В DES лавинный эффект - строгий, к 4-5 раунду при изменении одного входного бита или одного бита ключа проявляется лавинный эффект. \n",
    "\n",
    "> [Здесь можно посмотреть на таблицы влияния изменений](https://ru.wikipedia.org/wiki/%D0%9B%D0%B0%D0%B2%D0%B8%D0%BD%D0%BD%D1%8B%D0%B9_%D1%8D%D1%84%D1%84%D0%B5%D0%BA%D1%82#%D0%9B%D0%B0%D0%B2%D0%B8%D0%BD%D0%BD%D1%8B%D0%B9_%D1%8D%D1%84%D1%84%D0%B5%D0%BA%D1%82_%D0%B2_DES)\n",
    "\n",
    "</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
